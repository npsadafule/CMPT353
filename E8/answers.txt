1. Which model did the best for the colour-prediction task? Can you give a theory about why? Do you have any theory about why RGB/LAB/HSV worked better for different models?

    In my case, the k-Nearest Neighbors (kNN) classifier gave the best results, with an accuracy of 0.757 for RGB and 0.755 for LAB. This might be because kNN works well with how colours are spread out in both spaces, using distance to make predictions. The Random Forest classifier also did quite well, performing better in LAB (0.759) than in RGB (0.747). LAB might have worked better because it represents colours in a way that's more similar to how humans see them, making it easier for the model to split the data correctly. The Naive Bayes classifier improved a lot from RGB (0.563) to LAB (0.626), likely because LAB handles colour differences more uniformly. I didn't try HSV, but LAB seems to be a good choice for models that need to make sense of colours the way humans do.

2. Have a look at the cities in your validation data where the weather model makes the wrong prediction. Do you feel like the model is making reasonable mistakes? Can you think of any weather features that we could potentially add to make better predictions?

    I think the model's mistakes are reasonable. My last model had an accuracy of 0.782, meaning it got about 78.2% of predictions right. This shows that the model is doing a decent job but could still be improved. The errors are understandable, especially for cities with similar weather patterns. For example, the model often confused Edmonton with Calgary or Montreal with Ottawa. These pairs of cities are geographically close and have similar climates, so the model's confusion is understandable. To improve predictions, we could include features like wind patterns, elevation differences, or detailed descriptions of extreme weather events. These additional data points could make the model more effective at distinguishing between cities with otherwise similar weather profiles.